{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "house = pd.read_csv(\"/Users/wxu/workspace/regression/week6/kc_house_data_small.csv\",sep=\",\",header=0,dtype = dtype_dict)\n",
    "test = pd.read_csv(\"/Users/wxu/workspace/regression/week6/kc_house_data_small_test.csv\",sep=\",\",header=0,dtype = dtype_dict)\n",
    "validation =  pd.read_csv(\"/Users/wxu/workspace/regression/week6/kc_house_data_validation.csv\",sep=\",\",header=0,dtype = dtype_dict)\n",
    "train = pd.read_csv(\"/Users/wxu/workspace/regression/week6/kc_house_data_small_train.csv\",sep=\",\",header= 0,dtype = dtype_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, output):\n",
    "    \n",
    "    dataframe['constant']=1\n",
    "    features = ['constant'] + features\n",
    "    features_matrix = dataframe[features].as_matrix()\n",
    "    output_array = list(dataframe[output])\n",
    "    \n",
    "    return (features_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    norm_features = feature_matrix/norms\n",
    "    return (norm_features,norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n",
    "            'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n",
    "            'yr_renovated', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "train_feature,train_output = get_numpy_data(train,features,\"price\")\n",
    "test_feature,test_output = get_numpy_data(test,features,\"price\")\n",
    "validation_feature,validation_output = get_numpy_data(validation,features,\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train_norm, norms = normalize_features(train_feature)\n",
    "features_test_norm = test_feature / norms\n",
    "features_valid_norm = validation_feature / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n",
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print features_test_norm[0]\n",
    "print features_train_norm[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060274709163\n"
     ]
    }
   ],
   "source": [
    "print math.sqrt(sum((features_test_norm[0]-features_train_norm[0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06027470916295592, 0.08546881147643746, 0.06149946435279315, 0.05340273979294363, 0.05844484060170442, 0.059879215098128345, 0.05463140496775461, 0.05543108323614607, 0.052383627840220305, 0.05972359371398078]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 3, 6, 7, 4, 9, 5, 0, 2, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quiz1\n",
    "\n",
    "distance = [0]*10\n",
    "for i in range(10):\n",
    "    distance[i]= math.sqrt(sum((features_test_norm[0]-features_train_norm[i])**2))\n",
    "print distance\n",
    "np.argsort(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quiz2,3\n",
    "def compute_distances(features_instances, features_query):\n",
    "    #features_Instance: train data features\n",
    "    #features_query: the feature related to the queried house\n",
    "    #return a list of distance that contains the distance between the queried house and each training houes\n",
    "    distance = np.sum((features_query-features_instances)**2,axis = 1)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 382 1149 4087 ..., 1107 5226 2486]\n",
      "[ 249000.]\n"
     ]
    }
   ],
   "source": [
    "neighbor1 = compute_distances(features_instances = features_train_norm, features_query = features_test_norm[2])\n",
    "mysort = np.argsort(neighbor1)\n",
    "print mysort\n",
    "print train_output[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 382 1149 4087 3142]\n"
     ]
    }
   ],
   "source": [
    "#quiz4 knn\n",
    "def k_nearest_neighbors(k, features_instances, features_query):\n",
    "    distance = np.sum((features_query-features_instances)**2,axis = 1)\n",
    "    sort = np.argsort(distance)\n",
    "    neighbors = sort[0:k]\n",
    "    return neighbors\n",
    "print k_nearest_neighbors(4, features_train_norm, features_test_norm[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413987.5\n"
     ]
    }
   ],
   "source": [
    "#quiz5\n",
    "def predict_output_of_query(k, features_instances, output_train, features_query):\n",
    "    #features_instances:normalized train features\n",
    "    #output_train price\n",
    "    distance = np.sum((features_query-features_instances)**2,axis = 1)\n",
    "    sort = np.argsort(distance)\n",
    "    nearestneighborsIndex = sort[0:k]\n",
    "    output_train = np.asarray(output_train)\n",
    "    prediction = np.mean(output_train[nearestneighborsIndex])\n",
    "    return prediction\n",
    "\n",
    "print predict_output_of_query(4, features_train_norm, train_output, features_test_norm[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_output(k, features_instances, output_train, features_query_instances):\n",
    "    predDist = [0]*features_query_instances.shape[0]\n",
    "    for i in range(features_query_instances.shape[0]):\n",
    "        curr_query = features_query_instances[i]\n",
    "        #curr_query.shape = [1,18]\n",
    "        predDist[i] = predict_output_of_query(k, features_instances, output_train, curr_query)\n",
    "    \n",
    "    return predDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[881300.0, 431860.0, 460595.0, 430200.0, 766750.0, 667420.0, 350032.0, 512800.70000000001, 484000.0, 457235.0]\n"
     ]
    }
   ],
   "source": [
    "trial = features_test_norm[0:10,]\n",
    "predTrial = predict_output(k=10, features_instances=features_train_norm,\n",
    "                           output_train=train_output, features_query_instances=trial)\n",
    "print predTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105453830251561.0, 83445073504025.5, 72692096019202.797, 71946721652091.688, 69846517419718.586, 68899544353181.094, 68341973450051.055, 67361678735491.5, 68372727958976.336, 69335048668556.703, 69523855215598.875, 69049969587246.453, 70011254508263.625, 70908698869034.438, 71106928385945.359]\n"
     ]
    }
   ],
   "source": [
    "rss_valid = [0]*15\n",
    "for k1 in range(1,16):\n",
    "    currK_pred_valid = predict_output(k=k1, features_instances=features_train_norm,\n",
    "                                     output_train=train_output, features_query_instances = features_valid_norm)\n",
    "    currK_pred_valid_array = np.asarray(currK_pred_valid)\n",
    "    valid_true_array = np.asarray(validation_output)\n",
    "    rss_valid[k1-1] = sum((currK_pred_valid_array-valid_true_array)**2)\n",
    "print rss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  6,  8,  5, 11,  9, 10,  4, 12, 13, 14,  3,  2,  1,  0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rssValid = np.asarray(rss_valid)\n",
    "np.argsort(rssValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_k=range(1,16)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33118823552e+14\n"
     ]
    }
   ],
   "source": [
    "currK_pred_test = predict_output(k=select_k, features_instances=features_train_norm,\n",
    "                                     output_train=train_output, features_query_instances = features_test_norm)\n",
    "currK_pred_test_array = np.asarray(currK_pred_test)\n",
    "test_true_array = np.asarray(test_output)\n",
    "rss_valid = sum((currK_pred_test_array-test_true_array)**2)\n",
    "print rss_valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
